# PLLE Agent configuration for chain MDP

# General
main.random_episodes = 50
main.episodes        = 50
main.agent           = @BDRL_agent
main.env             = 'ChainMDP-v0'
main.render          = True
main.render_training = False
main.logfile         = 'results/chain_bdrl.csv'

# Network
BDR.inducing_batch = 30
BDR.N              = 5
BDR.layer_sizes    = (50,)
BDR.inducing_data  = None
BDR.dtype          = %float32
BDR.device         = 'cpu'
BDR.f_postproc     = 'sort'

# Agent
BDRL_agent.train_batch       = 10
BDRL_agent.seed              = 42
BDRL_agent.dtype             = %float32
BDRL_agent.device            = 'cpu'
BDRL_agent.storage_device    = 'cpu'
BDRL_agent.opt               = @adam
BDRL_agent.lr                = 0.05
BDRL_agent.gamma             = 0.99
BDRL_agent.S_eval            = 80
BDRL_agent.S_train           = 15
BDRL_agent.N_train           = 20
BDRL_agent.S_explore         = 1
BDRL_agent.scale_rewards     = False
BDRL_agent.train_steps_per_transition = 10

# Reward Scaling
RewardScaler.min       = -1
RewardScaler.max       = 1
RewardScaler.scale_min = -1
RewardScaler.scale_max = 1

# Environment
ChainMDP.length         = 1
ChainMDP.num_pts_render = 100
