{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Gamma\n",
    "\n",
    "import bayesfunc as bf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from ipywidgets import interact_manual, interact, FloatSlider, IntSlider\n",
    "\n",
    "dtype=t.float64\n",
    "device=\"cpu\"\n",
    "#device=\"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa520c52e80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_features = 1\n",
    "out_features = 1\n",
    "train_batch = 40\n",
    "batches = 3\n",
    "data_size = batches * train_batch\n",
    "\n",
    "t.manual_seed(0)\n",
    "\n",
    "def generate_data():\n",
    "    noise = Gamma(2, 0.1)\n",
    "    X = t.rand(data_size, in_features) * 4 - 2\n",
    "    x_1 = X[:int(data_size/2), :]\n",
    "    x_2 = X[int(data_size/2):, :]\n",
    "    \n",
    "    y = t.cat((\n",
    "        x_1**3 + 20 + 0.1 * noise.sample((int(data_size/2), in_features)),\n",
    "        x_2**3 - 20 - 0.1 * noise.sample((int(data_size/2), in_features))\n",
    "    ))\n",
    "    \n",
    "    scale = y.std()\n",
    "    y = y/scale\n",
    "    \n",
    "    xys = t.cat((X,y),1)\n",
    "    xys = xys[t.randperm(xys.size()[0])]\n",
    "    X = xys[:,0].unsqueeze(1).to(device=device, dtype=dtype)\n",
    "    y = xys[:,1].unsqueeze(1).to(device=device, dtype=dtype)\n",
    "    return X, y, scale\n",
    "\n",
    "X, y, scale = generate_data()\n",
    "\n",
    "plt.scatter(X.detach().cpu(), y.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model the probability of the outcome variable $y$ as\n",
    "$$\n",
    "P(y) = \\frac{1}{Z}\\prod^N_{i=1}P_i(y),\n",
    "$$\n",
    "writing the corresponding log-probability as\n",
    "$$\n",
    "\\mathcal{L}(y) = \\sum^N_{i=1}\\mathcal{L}_i(y) - \\log Z\n",
    "$$\n",
    "where each $L_i(y)$ is of the form:\n",
    "$$\n",
    "\\mathcal{L}(y) = \\sum^N_{i=1} - (y-f_i)\\left(\\alpha_i \\Theta(y-f_i) - \\beta_i\\Theta(y-f_i)\\right) - \\log Z,\n",
    "$$\n",
    "where $\\Theta(u)$ is Heaviside step with value $1$ if $u>0$ and $0$ otherwise, $\\alpha_i > 0$ and $\\beta_i > 0$ for all $i \\in [1, N]$ and we also assume $f_i$ are ordered; that is, $f_i \\le f_{i+1}$ for all $i \\in [1,N]$. Crucially each of these terms in the summand is negative for all values of $y$, hence the probability is a valid member of the exponential family of distributions.\n",
    "\n",
    "The normalising term $Z$ is found as\n",
    "$$\n",
    "Z = \\frac{1}{a_0}e^{a_0f_1+b_0} + \\sum^{N-1}_{j=1}\\frac{1}{a_j}e^{b_j}\\left(e^{a_jf_{j+1}}-e^{a_jf_j}\\right) - \\frac{1}{a_N}e^{a_Nf_N + b_N},\n",
    "$$\n",
    "where\n",
    "\\begin{align*}\n",
    "a_j &= \\sum^N_{i=j+1}\\beta_i - \\sum^j_{i=1}\\alpha_i \\\\\n",
    "b_j &= \\sum^j_{i=1}\\alpha_if_i - \\sum^N_{i=j+1}\\beta_if_i,\n",
    "\\end{align*}\n",
    "In particular, we have the following edge cases which can be written explicitly; for $j=0$:\n",
    "$$\n",
    "a_0 = \\sum^N_{i=1}\\beta_i,\\ \\ \\ \\ b_0 = -\\sum^N_{i=1}\\beta_if_i\n",
    "$$\n",
    "and for $j=N$:\n",
    "$$\n",
    "a_N = -\\sum^N_{i=1}\\alpha_i,\\ \\ \\ \\ b_N = \\sum^N_{i=1}\\alpha_if_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enforce the constraints on the values of $\\mathbf{f}$, $\\mathbf{\\alpha}$ and $\\mathbf{\\beta}$, we first ensure that each are positive. Let the $\\mathbf{f}$ values returned from the network be denoted $\\hat{f}$. The ordering constraint on $f$ is enforced by additionally outputting a base value $r$ to which $\\hat{f}_1$ is added, giving $f_1 = r + \\hat{f}_1$. Subsequent $f_i$ for $i > 1$ can be recovered by finding the cumulative sum $f_i = f_{i-1} + \\hat{f}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can devise a simple dynamic programming algorithm to compute these normalising terms $a_j$ and $b_j$ efficiently by computing vectors of their partial sums in $O(n)$ time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b980790c014273b0130e5bde5926f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inducing_batch = 40\n",
    "\n",
    "# number of fs, alphas and betas\n",
    "N = 10\n",
    "\n",
    "# Select Data\n",
    "data_X = X\n",
    "data_y = y\n",
    "scale = scale\n",
    "\n",
    "class NET(nn.Module):\n",
    "    \"\"\"Yet unnamed, newfangled neural network thing\"\"\"\n",
    "    def __init__(self, inducing_batch, N):\n",
    "        hidden = 50\n",
    "        super(NET, self).__init__()\n",
    "        inducing_data = t.linspace(data_X.min(), data_X.max(), inducing_batch).unsqueeze(1)\n",
    "        self.ia = bf.InducingAdd(inducing_batch=inducing_batch, inducing_data=inducing_data)\n",
    "        self.ir = bf.InducingRemove(inducing_batch=inducing_batch)\n",
    "        \n",
    "        self.fc1 = bf.GILinear(in_features=1, out_features=hidden, inducing_batch=inducing_batch, bias=True)\n",
    "        self.offset = bf.GILinear(in_features=hidden, out_features=1, inducing_batch=inducing_batch, bias=True, full_prec=True)\n",
    "        self.f = bf.GILinear(in_features=hidden, out_features=N, inducing_batch=inducing_batch, bias=True, full_prec=True)\n",
    "        self.alpha = bf.GILinear(in_features=hidden, out_features=N, inducing_batch=inducing_batch, bias=True, full_prec=True)\n",
    "        self.beta = bf.GILinear(in_features=hidden, out_features=N, inducing_batch=inducing_batch, bias=True, full_prec=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ia(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # this can be positive or negative\n",
    "        offset = self.ir(self.offset(x))\n",
    "        # the following _must_ be non-negative, here we use softplus\n",
    "        f = self.ir(F.softplus(self.f(x)))\n",
    "        alpha = self.ir(F.softplus(self.alpha(x)))\n",
    "        beta = self.ir(F.softplus(self.beta(x)))\n",
    "        return offset, f, alpha, beta\n",
    "    \n",
    "net = NET(inducing_batch, N).to(device=device, dtype=dtype)\n",
    "\n",
    "samples = 10\n",
    "opt = t.optim.Adam(net.parameters(), lr=0.05)\n",
    "for i in tqdm(range(500)):\n",
    "    for batch in range(batches):\n",
    "        l = batch * train_batch\n",
    "        u = l     + train_batch\n",
    "        batch_X = data_X[l:u].expand(samples, -1, -1)\n",
    "        batch_y = data_y[l:u].expand(samples, -1, -1)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        (offset, f, alpha, beta), logpq, _ = bf.propagate(net, batch_X)\n",
    "        \n",
    "        # Add an offset to f_0 for all samples, and all points in the batch\n",
    "        offset = t.cat((\n",
    "            offset,\n",
    "            t.zeros_like(offset).expand(-1, -1, N-1).to(dtype=dtype, device=device)\n",
    "        ),2)\n",
    "        f = f + offset\n",
    "        # Find the cumulative sum to ensure f_i <= f_{i+1}\n",
    "        f = f.cumsum(2)\n",
    "        \n",
    "        # Log-likelihood terms\n",
    "        res = batch_y - f\n",
    "        ll_terms = -(res) * t.where(res > 0, alpha, -beta)\n",
    "        \n",
    "        # Calculating the normalising term ------------------------------------\n",
    "        \n",
    "        # Flip these matrices along third dimension by copying memory; O(n)\n",
    "        b_flip = beta.flip(2)\n",
    "        f_flip = f.flip(2)\n",
    "        \n",
    "        # Calculate vectors of partial sums ('_ps') in O(n) time\n",
    "        a_ps = alpha.cumsum(2)\n",
    "        b_ps = b_flip.cumsum(2).flip(2)\n",
    "        af_ps = (alpha*f).cumsum(2)\n",
    "        bf_ps = (b_flip * f_flip).cumsum(2).flip(2)\n",
    "\n",
    "        # Calculate main coefficient vectors\n",
    "        a_vec  = b_ps[:,:,1:] - a_ps[:,:,:-1]\n",
    "        b_vec  = af_ps[:,:,:-1] - bf_ps[:,:,1:]\n",
    "        \n",
    "        # Calculate terms for interval y \\in (-\\infty, f_1]\n",
    "        a_0 = b_ps[:,:,0]\n",
    "        b_0 = - bf_ps[:,:,0]\n",
    "        a_N = - a_ps[:,:,-1]\n",
    "        b_N = af_ps[:,:,-1]\n",
    "        \n",
    "        # Calculate the normalising term\n",
    "        Z = 1/a_0 * t.exp(a_0 * f[:,:,0] + b_0)\n",
    "        Z = Z + (1/a_vec * t.exp(b_vec)*(t.exp(a_vec * f[:,:,1:])-t.exp(a_vec*f[:,:,:-1]))).sum(2)\n",
    "        Z = Z - (1/a_N * t.exp(a_N * f[:,:,N-1] + b_N))\n",
    "                        \n",
    "        lls = ll_terms.sum(-1) - t.log(Z)\n",
    "        ll = lls.mean(-1)\n",
    "        assert ll.shape == (samples,)\n",
    "        assert logpq.shape == (samples,)\n",
    "        elbo = ll + logpq/data_size\n",
    "        \n",
    "        (-elbo.mean()).backward()\n",
    "        opt.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c63efe5a6c4f949c74be72128576dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x_loc', max=1.9882662296295166, min=-1.9950559139251…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_density(x_loc)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pts = 100\n",
    "\n",
    "def plot_density(x_loc):\n",
    "    # The number of points to plot the quantile function at (ys)\n",
    "    with t.no_grad():\n",
    "        samples = 100\n",
    "        xs = t.tensor([x_loc]).unsqueeze(1).to(dtype=dtype, device=device)\n",
    "        ys = t.linspace(-5, 5, num_pts).unsqueeze(1).to(dtype=dtype, device=device)\n",
    "        xs = xs.expand(samples, -1, -1)\n",
    "        ys = ys.expand(samples, -1, -1)\n",
    "        (ref, f, alpha, beta), _, _ = bf.propagate(net, xs)\n",
    "        \n",
    "        offset = t.cat((\n",
    "            ref,\n",
    "            t.zeros_like(ref).expand(-1, -1, N-1).to(dtype=dtype, device=device)\n",
    "        ),2)\n",
    "        f = f + offset\n",
    "        # Find the cumulative sum to ensure f_i <= f_{i+1}\n",
    "        f = f.cumsum(2)\n",
    "        \n",
    "        # Log-likelihood terms\n",
    "        res = ys - f\n",
    "        # TODO exponentiate here\n",
    "        ll_terms = -(res) * t.where(res > 0, alpha, -beta)\n",
    "        \n",
    "        # Calculating the normalising term ------------------------------------\n",
    "        \n",
    "        # Flip these matrices along third dimension by copying memory; O(n)\n",
    "        b_flip = beta.flip(2)\n",
    "        f_flip = f.flip(2)\n",
    "        \n",
    "        # Calculate vectors of partial sums O(n)\n",
    "        a_ps = alpha.cumsum(2)\n",
    "        b_ps = b_flip.cumsum(2).flip(2)\n",
    "        af_ps = (alpha*f).cumsum(2)\n",
    "        bf_ps = (b_flip * f_flip).cumsum(2).flip(2)\n",
    "\n",
    "        # Calculate main coefficient vectors\n",
    "        a_vec  = b_ps[:,:,1:] - a_ps[:,:,:-1]\n",
    "        b_vec  = af_ps[:,:,:-1] - bf_ps[:,:,1:]\n",
    "        \n",
    "        # Calculate terms for interval y \\in (-\\infty, f_1]\n",
    "        a_0 = b_ps[:,:,0]\n",
    "        b_0 = - bf_ps[:,:,0]\n",
    "        a_N = - a_ps[:,:,-1]\n",
    "        b_N = af_ps[:,:,-1]\n",
    "        \n",
    "        # Calculate the normalising term\n",
    "        Z = 1/a_0 * t.exp(a_0 * f[:,:,0] + b_0)\n",
    "        Z = Z + (1/a_vec * t.exp(b_vec)*(t.exp(a_vec * f[:,:,1:])-t.exp(a_vec*f[:,:,:-1]))).sum(2)\n",
    "        Z = Z - (1/a_N * t.exp(a_N * f[:,:,N-1] + b_N))\n",
    "                        \n",
    "        ls = t.exp(ll_terms.sum(-1) - t.log(Z))\n",
    "        l = ls.mean(0).detach().cpu()\n",
    "        std = ls.std(0).detach().cpu()\n",
    "        \n",
    "        plt.plot(ys[0].detach().cpu(), l)\n",
    "        plt.fill_between(ys[0].detach().cpu().squeeze(), (l+2*std).squeeze(), (l-2*std).squeeze(), alpha=0.2)\n",
    "        plt.title(f\"Distribution at x={x_loc}\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Y value\")\n",
    "\n",
    "interact(plot_density, x_loc=FloatSlider(min=data_X.min(), max=data_X.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
